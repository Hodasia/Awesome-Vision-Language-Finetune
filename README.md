# Awesome Vision Language Prompt/Finetune/Adapter

We summerize awesome **Vision Language(VL) Prompt/Finetune/Adapter** methods and models. The list of papers is in chronological order.

# Timeline

[*2023*](https://www.notion.so/Awesome-Vision-Language-Prompt-Finetune-Adapter-0b4745b39c4948a6963eaacf2361af44)

[*2022*](https://www.notion.so/Awesome-Vision-Language-Prompt-Finetune-Adapter-0b4745b39c4948a6963eaacf2361af44)

[*2021*](https://www.notion.so/Awesome-Vision-Language-Prompt-Finetune-Adapter-0b4745b39c4948a6963eaacf2361af44)

# 2023

1. ****Dual Modality Prompt Tuning for Vision-Language Pre-Trained Model**** [*[CVPR]*](https://arxiv.org/abs/2208.08340) [*[code]*](https://github.com/fanrena/DPT) 
    <p align="center"><img width="50%" src="https://github.com/Hodasia/Awesome-Vision-Language-Finetune/blob/main/img/Untitled.png" /></p>
    
2. ****Scaling & Shifting Your Features: A New Baseline for Efficient Model Tuning**** [*[NeurlPS]*](https://arxiv.org/abs/2210.08823) [*[code]*](https://github.com/dongzelian/SSF) 
    <p align="center"><img width="30%" src="https://github.com/Hodasia/Awesome-Vision-Language-Finetune/blob/main/img/Untitled%201.png" /></p>
    
3. ****Debiasing Vision-Language Models via Biased Prompts**** [*[arXiv]*](https://arxiv.org/abs/2302.00070) [*[code]*](https://github.com/chingyaoc/debias_vl)

    <p align="center"><img width="50%" src="https://github.com/Hodasia/Awesome-Vision-Language-Finetune/blob/main/img/Untitled%202.png" /></p>

4. ****PLOT: Prompt Learning with Optimal Transport for Vision-Language Models**** [*[ICLR]*](https://arxiv.org/abs/2210.01253) [*[code]*](https://github.com/CHENGY12/PLOT)
    
    <p align="center"><img width="50%" src="https://github.com/Hodasia/Awesome-Vision-Language-Finetune/blob/main/img/Untitled%203.png" /></p>
    
5. ****VoLTA: Vision-Language Transformer with Weakly-Supervised Local-Feature Alignment**** [*[arXiv]*](https://arxiv.org/abs/2210.04135)
    
    <p align="center"><img width="50%" src="https://github.com/Hodasia/Awesome-Vision-Language-Finetune/blob/main/img/Untitled%204.png" /></p>
    
6. ****CLIP-ViP: Adapting Pre-trained Image-Text Model to Video-Language Representation Alignment**** [*[ICLRr]*](https://arxiv.org/abs/2209.06430) [*[code]*](https://github.com/microsoft/XPretrain/tree/main/CLIP-ViP)
    
    <p align="center"><img width="50%" src="https://github.com/Hodasia/Awesome-Vision-Language-Finetune/blob/main/img/Untitled%205.png" /></p>
    
7. ****SgVA-CLIP: Semantic-guided Visual Adapting of Vision-Language Models for Few-shot Image Classification**** [*[arXiv]*](https://arxiv.org/abs/2211.16191)
    
    <p align="center"><img width="50%" src="https://github.com/Hodasia/Awesome-Vision-Language-Finetune/blob/main/img/Untitled%206.png" /></p>
    
8. ****Understanding and Mitigating Overfitting in Prompt Tuning for Vision-Language Models**** [*[arXiv]*](https://arxiv.org/abs/2211.02219) [*[code]*](https://tinyurl.com/mpe64f89)
    
    <p align="center"><img width="50%" src="https://github.com/Hodasia/Awesome-Vision-Language-Finetune/blob/main/img/Untitled%207.png" /></p>
    
9. ****Re-ViLM: Retrieval-Augmented Visual Language Model for Zero and Few-Shot Image Captioning**** [*[arXiv]*](https://arxiv.org/abs/2302.04858) 
    
    <p align="center"><img width="50%" src="https://github.com/Hodasia/Awesome-Vision-Language-Finetune/blob/main/img/Untitled%208.png" /></p>
    
10. ****VoP: Text-Video Co-operative Prompt Tuning for Cross-Modal Retrieval**** [*[CVPR]*](https://arxiv.org/abs/2211.12764) [*[code]*](https://github.com/bighuang624/VoP)
    
    <p align="center"><img width="50%" src="https://github.com/Hodasia/Awesome-Vision-Language-Finetune/blob/main/img/Untitled%209.png" /></p>
    
11. ****Contrastive Prompt Tuning Improves Generalization in Vision-Language Models**** [*[ICLR]*](https://openreview.net/forum?id=g4JB0ksCrKe)
    
    <p align="center"><img width="50%" src="https://github.com/Hodasia/Awesome-Vision-Language-Finetune/blob/main/img/Untitled%2010.png" /></p>
    
12. ****Vision Transformer Adapter for Dense Predictions**** [*[ICLR]*](https://arxiv.org/abs/2205.08534) [*[code]*](https://github.com/czczup/ViT-Adapter)
    
    <p align="center"><img width="50%" src="https://github.com/Hodasia/Awesome-Vision-Language-Finetune/blob/main/img/Untitled%2011.png" /></p>
    
13. ****T2I-Adapter: Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion Models**** [*[arXiv]*](https://arxiv.org/abs/2302.08453) [*[code]*](https://github.com/TencentARC/T2I-Adapter)
    
    <p align="center"><img width="50%" src="https://github.com/Hodasia/Awesome-Vision-Language-Finetune/blob/main/img/Untitled%2012.png" /></p>
    
14. ****Debiased Fine-Tuning for Vision-language Models by Prompt Regularization**** [*[arXiv]*](https://arxiv.org/abs/2301.12429)
    
    <p align="center"><img width="50%" src="https://github.com/Hodasia/Awesome-Vision-Language-Finetune/blob/main/img/Untitled%2013.png" /></p>
    
15. ****Fine-tuned CLIP Models are Efficient Video Learners**** [*[CVPR]*](https://arxiv.org/abs/2212.03640) [*[code]*](https://github.com/muzairkhattak/ViFi-CLIP) 
    
    <p align="center"><img width="30%" src="https://github.com/Hodasia/Awesome-Vision-Language-Finetune/blob/main/img/Untitled%2014.png" /></p>
    

# 2022

1. **Learning to Prompt for Continual Learning** [*[paper]](https://arxiv.org/abs/2112.08654) [[code]](https://github.com/google-research/l2p) CVPR*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2015.png)
    
2. **Visual Prompt Tuning** [*[paper]](https://arxiv.org/abs/2203.12119) [[code]](https://github.com/kmnp/vpt) ECCV*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2016.png)
    
3. **Unified Vision and Language Prompt Learning  ***[[paper]](https://arxiv.org/abs/2210.07225) [[code]](https://github.com/yuhangzang/UPT) CVPR*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2017.png)
    
4. ****AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition**** [*[paper]](https://arxiv.org/abs/2205.13535) [[code]](https://github.com/ShoufaChen/AdaptFormer) NeurlPS*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2018.png)
    
5. ****Neural Prompt Search**** [*[paper]](https://arxiv.org/abs/2206.04673) [[code]](https://github.com/ZhangYuanhan-AI/NOAH) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2019.png)
    
6. ****Convolutional Bypasses Are Better Vision Transformer Adapters**** [*[paper]](https://arxiv.org/abs/2207.07039) [[code]](https://github.com/JieShibo/PETL-ViT) arXiv*

![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2020.png)

![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2021.png)

1. ****Conv-Adapter: Exploring Parameter Efficient Transfer Learning for ConvNets**** [*[paper]](https://arxiv.org/abs/2208.07463) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2022.png)
    
2. ****ST-Adapter: Parameter-Efficient Image-to-Video Transfer Learning**** [*[paper]](https://arxiv.org/abs/2206.13559) [[code]](https://github.com/linziyi96/st-adapter) NeurlPS*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2023.png)
    
3. ****Parameter-efficient Model Adaptation for Vision Transformers**** [*[paper]](https://arxiv.org/abs/2203.16329) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2024.png)
    
4. ****VL-Adapter: Parameter-Efficient Transfer Learning for Vision-and-Language Tasks**** [*[paper]](https://arxiv.org/abs/2112.06825) [[code]](https://github.com/ylsung/VL_adapter) CVPR*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2025.png)
    
5. ****Prompt Vision Transformer for Domain Generalization**** [[paper]](https://arxiv.org/abs/2208.08914) arXiv
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2026.png)
    
6. ****Visual Prompt Tuning for Generative Transfer Learning**** [*[paper]](https://arxiv.org/abs/2210.00990) technical report*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2027.png)
    
7. ****Learning Domain Invariant Prompt for Vision-Language Models**** [*[paper]](https://arxiv.org/abs/2212.04196) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2028.png)
    
8. ****Domain-Unified Prompt Representations for Source-Free Domain Generalization**** [*[paper]](https://arxiv.org/abs/2209.14926) [[code]](https://github.com/muse1998/Source-Free-Domain-Generalization) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2029.png)
    
9. ****Prompt-Matched Semantic Segmentation**** [*[paper]](https://arxiv.org/abs/2208.10159) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2030.png)
    
10. ****Visual Prompting via Image Inpainting**** [[paper]](https://arxiv.org/abs/2209.00647) 
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2031.png)
    
11. ****Unleashing the Power of Visual Prompting At the Pixel Level**** [*[paper]](https://arxiv.org/abs/2212.10556) [[code]](https://github.com/UCSC-VLAA/EVP) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2032.png)
    
12. ****Exploring Visual Prompts for Adapting Large-Scale Models**** [*[paper]](https://arxiv.org/abs/2203.17274) [[code]](http://hjbahng.github.io/visual_prompting) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2033.png)
    
13. ****Visual Prompt Tuning for Test-time Domain Adaptation**** [*[paper]](https://arxiv.org/abs/2210.04831) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2034.png)
    
14. ****Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models**** [*[paper]](https://arxiv.org/abs/2209.07511) [[code]](https://azshue.github.io/TPT) NeurlPS*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2035.png)
    
15. ****Prompt Generation Networks for Efficient Adaptation of Frozen Vision Transformers**** [*[paper]](https://arxiv.org/abs/2210.06466) [[code]](https://github.com/jochemloedeman/PGN) Tech report*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2036.png)
    
16. **Multitask Vision-Language Prompt Tuning** [*[paper]](https://arxiv.org/abs/2211.11720) [[code]](https://github.com/sIncerass/MVLPT) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2037.png)
    
17. ****Prompt Tuning with Soft Context Sharing for Vision-Language Models**** [*[paper]](https://arxiv.org/abs/2208.13474) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2038.png)
    
18. ****Learning to Prompt for Vision-Language Models**** [*[paper]](https://arxiv.org/abs/2109.01134) [[code]](https://github.com/KaiyangZhou/CoOp) IJCV*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2039.png)
    
19. ****Language-Aware Soft Prompting for Vision & Language Foundation Models**** [*[paper]](https://arxiv.org/abs/2210.01115) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2040.png)
    
20. ****Supporting Vision-Language Model Inference with Causality-pruning Knowledge Prompt**** [*[paper]](https://arxiv.org/abs/2205.11100) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2041.png)
    
21. ****Learning to Prompt for Open-Vocabulary Object Detection with Vision-Language Model**** [*[paper]](https://arxiv.org/abs/2203.14940) [[code]](https://github.com/dyabel/detpro) CVPR*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2042.png)
    
22. **A Good Prompt Is Worth Millions of Parameters: Low-resource Prompt-based Learning for Vision-Language Models** [*[paper]](https://arxiv.org/abs/2110.08484) [[code]](https://github.com/woojeongjin/FewVLM) ACL*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2043.png)
    
23. ****Prompting through Prototype: A Prototype-based Prompt Learning on Pretrained Vision-Language Models**** [*[paper]](https://arxiv.org/abs/2210.10841) arXIv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2044.png)
    
24. ****Unsupervised Prompt Learning for Vision-Language Models**** [*[paper]](https://arxiv.org/abs/2204.03649) [[code]](https://github.com/tonyhuang2022/UPL) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2045.png)
    
25. ****Prompt Distribution Learning**** [*[paper]](https://arxiv.org/abs/2205.03340) CVPR*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2046.png)
    
26. **Conditional Prompt Learning for Vision-Language Models** [*[paper]](https://arxiv.org/abs/2203.05557) [[code]](https://github.com/KaiyangZhou/CoOp) CVPR*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2047.png)
    
27. ****DenseCLIP: Language-Guided Dense Prediction with Context-Aware Prompting**** [*[paper]](https://arxiv.org/abs/2112.01518) [[code]](https://github.com/raoyongming/DenseCLIP) CVPR*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2048.png)
    
28. ****CLIP also Understands Text: Prompting CLIP for Phrase Understanding**** [*[paper]](https://arxiv.org/abs/2210.05836) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2049.png)
    
29. ****Bridge-Prompt: Towards Ordinal Action Understanding in Instructional Videos**** [*[paper]](https://arxiv.org/abs/2203.14104) [[code]](https://github.com/ttlmh/Bridge-Prompt) CVPR*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2050.png)
    
30. ****Prompting Visual-Language Models for Efficient Video Understanding**** [*[paper]](https://arxiv.org/abs/2112.04478) ECCV*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2051.png)
    
31. ****PointCLIP V2: Adapting CLIP for Powerful 3D Open-world Learning**** [*[paper]](https://arxiv.org/abs/2211.11682) [[code]](https://github.com/yangyangyang127/PointCLIP_V2) CVPR*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2052.png)
    
32. ****SVL-Adapter: Self-Supervised Adapter for Vision-Language Pretrained Models**** [*[paper]](https://arxiv.org/abs/2210.03794) [[code]](https://github.com/omipan/svl_adapter) BMV*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2053.png)
    
33. ****Localized Latent Updates for Fine-Tuning Vision-Language Models**** [*[paper]](https://arxiv.org/abs/2212.06556) arXiv*
34. ****EfficientVLM: Fast and Accurate Vision-Language Models via Knowledge Distillation and Modal-adaptive Pruning**** [*[paper]](https://arxiv.org/abs/2210.07795)  [[code]](https://github.com/swaggy-TN/EfficientVLM)* *arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2054.png)
    
35. ****Can Language Understand Depth?**** [*[paper]](https://arxiv.org/abs/2207.01077) [[code]](https://github.com/Adonis-galaxy/DepthCLIP) ACM MM*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2055.png)
    
36. ****Prompting for Multi-Modal Tracking**** [*[paper]](https://arxiv.org/abs/2207.14571) ACM MM*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2056.png)
    
37. ****Expanding Language-Image Pretrained Models for General Video Recognition**** [*[paper]](https://arxiv.org/abs/2208.02816) [[code]](https://aka.ms/X-CLIP) ECCV*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2057.png)
    
38. ****Tip-Adapter: Training-free Adaption of CLIP for Few-shot Classification**** [*[paper]](https://arxiv.org/abs/2207.09519) [[code]](https://github.com/gaopengcuhk/Tip-Adapter) ECCV*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2058.png)
    
39. ****Adapting CLIP For Phrase Localization Without Further Training**** [*[paper]](https://arxiv.org/abs/2204.03647) [[code]](https://github.com/pals-ttic/adapting-CLIP) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2059.png)
    
40. ****CPT: Colorful Prompt Tuning for Pre-trained Vision-Language Models**** [*[paper]](https://arxiv.org/abs/2109.11797) [[code]](https://github.com/thunlp/CPT) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2060.png)
    
41. ****Domain Prompt Learning for Efficiently Adapting CLIP to Unseen Domains**** [*[paper]](https://arxiv.org/abs/2111.12853) [[code]](https://github.com/shogi880/DPLCLIP) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2061.png)
    
42. ****Clip-Tuning: Towards Derivative-free Prompt Learning with a Mixture of Rewards**** [*[paper]](https://arxiv.org/abs/2210.12050) EMNLP*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2062.png)
    
43. **Prompt-aligned Gradient for Prompt Tuning** [*[paper]](https://arxiv.org/abs/2205.14865) [[code]](https://github.com/BeierZhu/Prompt-align) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2063.png)
    
44. ****DualCoOp: Fast Adaptation to Multi-Label Recognition with Limited Annotations**** [*[paper]](https://arxiv.org/abs/2206.09541) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2064.png)
    
45. ****Delving into the Openness of CLIP**** [*[paper]](https://arxiv.org/abs/2206.01986) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2065.png)
    
46. ****OrdinalCLIP: Learning Rank Prompts for Language-Guided Ordinal Regression**** [*[paper]](https://arxiv.org/abs/2206.02338)  [[code]](https://github.com/xk-huang/OrdinalCLIP) NeurlPS*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2066.png)
    
47. ****Prompt Tuning for Generative Multimodal Pretrained Models**** [*[paper]](https://arxiv.org/abs/2208.02532) [[code]](https://github.com/OFA-Sys/OFA) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2067.png)
    
48. ****Contrastive Demonstration Tuning for Pre-trained Language Models**** [*[paper]](https://arxiv.org/abs/2204.04392) [[code]](https://github.com/zjunlp/PromptKG/tree/main/research/Demo-Tuning) EMNLP*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2068.png)
    
49. ****PPT: Pre-trained Prompt Tuning for Few-shot Learning**** [*[paper]*](https://arxiv.org/abs/2109.04332) [*[code]](http://github.com/thu-coai/PPT) ACL*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2069.png)
    
50. ****Pro-tuning: Unified Prompt Tuning for Vision Tasks**** [*[paper]](https://arxiv.org/abs/2207.14381) arXiv*

![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2070.png)

1. ****MaPLe: Multi-modal Prompt Learning**** [*[paper]](https://arxiv.org/abs/2210.03117) [[code]](https://tinyurl.com/2dzs8f3w) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2071.png)
    
2. ****Multi-Prompt Alignment for Multi-Source Unsupervised Domain Adaptation**** [*[paper]](https://arxiv.org/abs/2209.15210) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2072.png)
    
3. ****An Empirical Study of GPT-3 for Few-Shot Knowledge-Based VQA**** [*[paper]](https://arxiv.org/abs/2109.05014) [[code]](https://github.com/microsoft/PICa) AAAI*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2073.png)
    
4. ****VisualGPT: Data-efficient Adaptation of Pretrained Language Models for Image Captioning**** [*[paper]](https://arxiv.org/abs/2102.10407) [[code]](https://github.com/Vision-CAIR/VisualGPT) CVPR*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2074.png)
    
5. ****Flamingo: a Visual Language Model for Few-Shot Learning**** [*[paper]](https://arxiv.org/abs/2204.14198) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2075.png)
    
6. ****Visual Clues: Bridging Vision and Language Foundations for Image Paragraph Captioning**** [*[paper]](https://arxiv.org/abs/2206.01843) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2076.png)
    
7. ****DU-VLG: Unifying Vision-and-Language Generation via Dual Sequence-to-Sequence Pre-training**** [*[paper]](https://arxiv.org/abs/2203.09052) ACL*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2077.png)
    
8. ****Grounded Language-Image Pre-training**** [*[paper]](https://arxiv.org/abs/2112.03857) [[code]](https://github.com/microsoft/GLIP) CVPR*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2078.png)
    
9. ****GroupViT: Semantic Segmentation Emerges from Text Supervision**** [*[paper]](https://arxiv.org/abs/2202.11094) [[code]](https://github.com/NVlabs/GroupViT) CVPR*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2079.png)
    
10. ****Finetune like you pretrain: Improved finetuning of zero-shot vision models**** [*[paper]](https://arxiv.org/abs/2212.00638) [[code]](https://github.com/locuslab/FLYP) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2080.png)
    
11. ****CPL: Counterfactual Prompt Learning for Vision and Language Models**** [*[paper]](https://arxiv.org/abs/2210.10362)*  [[code]](https://github.com/eric-ai-lab/CPL)  *arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2081.png)
    
12. ****Zero-Shot Temporal Action Detection via Vision-Language Prompting**** [*[paper]](https://arxiv.org/abs/2207.08184) [[code]](https://github.com/sauradip/STALE) ECCV*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2082.png)
    

# 2021

1. ****AdaViT: Adaptive Vision Transformers for Efficient Image Recognition**** [*[paper]](https://arxiv.org/abs/2111.15668) CVPR*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2083.png)
    
2. ****Unified Multimodal Pre-training and Prompt-based Tuning for Vision-Language Understanding and Generation**** [*[paper]](https://arxiv.org/abs/2112.05587) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2084.png)
    
3. **Learning Transferable Visual Models From Natural Language Supervision** [*[paper]](https://arxiv.org/abs/2103.00020#) [[code]](https://github.com/OpenAI/CLIP) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2085.png)
    
4. ****CLIP-Adapter: Better Vision-Language Models with Feature Adapters**** [*[paper]](https://arxiv.org/abs/2110.04544) Technical Report*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2086.png)
    
5. **PointCLIP: Point Cloud Understanding by CLIP** [*[paper]](https://arxiv.org/abs/2112.02413) [[code]](https://github.com/ZrrSkywalker/PointCLIP) CVPR*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2087.png)
    
6. ****Tip-Adapter: Training-free CLIP-Adapter for Better Vision-Language Modeling**** [*[paper]](https://arxiv.org/abs/2111.03930) [[code]](https://github.com/gaopengcuhk/Tip-Adapter) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2088.png)
    
7. ****ActionCLIP: A New Paradigm for Video Action Recognition**** [*[paper]](https://arxiv.org/abs/2109.08472) [[code]](https://github.com/sallymmx/ActionCLIP.git) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2089.png)
    
8. ****Multimodal Few-Shot Learning with Frozen Language Models**** [*[paper]](https://arxiv.org/abs/2106.13884) NeurlPS*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2090.png)
    
9. ****ClipCap: CLIP Prefix for Image Captioning**** [*[paper]](https://arxiv.org/abs/2111.09734) [[code]](https://github.com/rmokady/CLIP_prefix_caption) arXiv*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2091.png)
    
10. ****Unifying Vision-and-Language Tasks via Text Generation**** [*[paper]](https://arxiv.org/abs/2102.02779) [[code]](https://github.com/j-min/VL-T5) ICML*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2092.png)
    
11. **StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery** [*[paper]](https://arxiv.org/abs/2103.17249) [[code]](https://github.com/orpatashnik/StyleCLIP) ICCV*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2093.png)
    
12. ****Align and Prompt: Video-and-Language Pre-training with Entity Prompts**** [*[paper]](https://arxiv.org/abs/2112.09583) [[code]](https://github.com/salesforce/ALPRO) CVPR*
    
    ![Untitled](Awesome%20Vision%20Language%20Prompt%20Finetune%20Adapter%200b4745b39c4948a6963eaacf2361af44/Untitled%2094.png)
